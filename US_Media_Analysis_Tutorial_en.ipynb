{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed37a67",
   "metadata": {},
   "source": [
    "# Analyzing the Discourse on 'Climate Change' in U.S. Media: A Basic Tutorial of How to Do Data Science With Python\n",
    "\n",
    "Version: 1.0 (8 August 2022)\n",
    "\n",
    "For a more detailed version, please see the corresponding tutorial on [Medium.com]().\n",
    "\n",
    "--------\n",
    "\n",
    "# Introduction\n",
    "\n",
    "## What is the aim of this tutorial?\n",
    "In this contribution, I will collect and analyze a small dataset consisting of news articles collected via an API to illustrate the typical pipeline for data-driven research:\n",
    "\n",
    "**Collecting Data** ➔ **Cleaning/Transforming Data** ➔ **Analyzing/Visualizing Data**\n",
    "\n",
    "The audience of this tutorial are beginners who just started doing data science with Python. My goal is to illustrate the overall approach mentioned above. Therefore, I will restrict the analysis to a few easy-to-understand methods. Yet, I hope to show that basic methods can lead to promising first results, even when applied on a rather small dataset.\n",
    "\n",
    "## How are we going to do this?\n",
    "In this tutorial, I will mainly be using [Jupyter](https://jupyter.org/) notebooks and the programming language [Python](https://www.python.org/).\n",
    "\n",
    "Jupyter Notebooks are interactive documents that can be displayed in the browser. Among other things, they allow the step-by-step execution of code in code cells as well as a detailled documentation of the code in text cells via [Markdown](https://www.markdownguide.org/). Jupyter notebooks are particularly suitable for data-driven research since they make each of the individual steps of the analysis tansparent while also enabling the presentation of the results in such a way that they can be understood by everyone, including people without any programming knowledge.\n",
    "\n",
    "The Jupyter notebook of this analysis is available on [GitHub](https://github.com/thomjur/climate_change_in_us_media_tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4be317",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data we'll be working with consists of English articles from well-known U.S. media websites that mention the term \"climate change,\" which I have collected using [News API's](https://newsapi.org/) *free tier*.\n",
    "\n",
    "In this case, an API (*application programming interface*) is an interface that enables programs or users to access and retrieve data from an external web server (usually in a JSON format). Regarding our example, querying the News API allows us to retrieve large amounts of article data in a semi-structured form using a simple HTTP query string. For the details of the queries, please see the\n",
    "\n",
    "A typical article that we collect via the News API looks like this:\n",
    "\n",
    "```Python\n",
    "{\n",
    "    \"source\": {\n",
    "        \"id\": \"reuters\",\n",
    "        \"name\": \"Reuters\"\n",
    "    },\n",
    "    \"author\": null,\n",
    "    \"title\": \"Wary shoppers muddy outlook for tech, auto firms in Asia - Reuters\",\n",
    "    \"description\": \"Asian tech firms from chipmaker Samsung to display panel maker [...]\",\n",
    "    \"urlToImage\": \"https://www.reuters.com/resizer/43w65Nb0zXMVr68fW8Al2pM83M8=/1200x628\",\n",
    "    \"publishedAt\": \"2022-07-28T08:02:00Z\",\n",
    "    \"content\": \"July 28 (Reuters) - Asian tech firms from chipmaker Samsung to display … [+5170 chars]\"\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "As we can see, it includes a lot of information. In this tutorial, we will focus on the title of the retrieved articles. The data basis of our analyis includes articles published between 22 June 2022 and 22 July 2022 from the following news websites:\n",
    "\n",
    "1. Fox News\n",
    "2. Breitbart\n",
    "3. The Washington Post\n",
    "4. CNN\n",
    "\n",
    "If you want to include other websites as well, you can easily retrieve additional data from other news websites via the News API. The collection of articles from the four websites was grouped into two corpora according to the general political orientation of the websites (right-wing/conservative vs. liberal): Fox News and Breitbart (**Corpus Conservative**, 195 articles) and The Washington Post and CNN (**Corpus Liberal**, 184 articles).\n",
    "\n",
    "\n",
    "# Research question and methods\n",
    "In this tutorial, the titles of the retrived article data will be examined. The following methods are used during the analysis and their results are visualized:\n",
    "\n",
    "1. **Named-Entity Recognition**.\n",
    "2. **Bag-of-Words**\n",
    "3. **Sentiment Analysis**\n",
    "\n",
    "Since the focus of this article lies on the interplay of the individual steps in the pipeline, the analysis methods were restricted to a selection of easy-to-understand and easy-to-implement techniques. For a mor in-depth analysis, please feel free to add additional methods, for example from the field of corpus linguistics or a complementary qualitative analysis in the sense of a *mixed-methods* approach. Also, it might make sense to increase the size and variets of the corpus data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbde01",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f82b6",
   "metadata": {},
   "source": [
    "# ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68803bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6ec4d",
   "metadata": {},
   "source": [
    "# 1. Collecting and Loading Data (News API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs news websites for News API\n",
    "\n",
    "NEWSPAGES_A = [\"fox-news\", \"breitbart-news\"]\n",
    "NEWSPAGES_B = [\"cnn\", \"the-washington-post\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af452fe",
   "metadata": {},
   "source": [
    "## 1.1 Collecting data via the News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc284e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation News API wrapper \n",
    "#newsapi = NewsApiClient(api_key='YOUR_KEY_GOES_HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b674a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data for Corpus Conservative\n",
    "\n",
    "for portal in NEWSPAGES_A:\n",
    "    all_articles = newsapi.get_everything(q='\\\"climate change\\\"',\n",
    "                                          sources=portal,\n",
    "                                         )\n",
    "    with open(portal+'.pkl', 'wb') as f:\n",
    "        pickle.dump(all_articles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollecting data for Corpus Liberal\n",
    "\n",
    "for portal in NEWSPAGES_B:\n",
    "    all_articles = newsapi.get_everything(q='\\\"climate change\\\"',\n",
    "                                          sources=portal,\n",
    "                                         )\n",
    "    with open(portal+'.pkl', 'wb') as f:\n",
    "        pickle.dump(all_articles, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bf3ca",
   "metadata": {},
   "source": [
    "## 1.2 Loading stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Corpus Conservative\n",
    "\n",
    "titles_corpus_A = list()\n",
    "for portal in NEWSPAGES_A:\n",
    "    with open(portal+'.pkl', \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        print(f'Loading data from {portal}.')\n",
    "        for article in data['articles']:\n",
    "            titles_corpus_A.append(article['title'])\n",
    "print(f'\\nEs liegen Daten zu {len(titles_corpus_A)} Artikel vor.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbad8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Corpus Liberal\n",
    "\n",
    "titles_corpus_B = list()\n",
    "for portal in NEWSPAGES_B:\n",
    "    with open(portal+'.pkl', \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        print(f'Loading data from {portal}.')\n",
    "        for article in data['articles']:\n",
    "            titles_corpus_B.append(article['title'])\n",
    "print(f'\\nEs liegen Daten zu {len(titles_corpus_B)} Artikel vor.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_corpus_B[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277527c",
   "metadata": {},
   "source": [
    "# 2. Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96659e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_A = nlp(\" \".join(titles_corpus_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b3bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_B = nlp(\" \".join(titles_corpus_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97c072",
   "metadata": {},
   "source": [
    "## 2.1 Named-Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed46732d",
   "metadata": {},
   "source": [
    "### NER: Corpus Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b41c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_A_NER_counter_text = Counter() \n",
    "corpus_A_NER_counter_label = Counter()\n",
    "\n",
    "for ent in docs_A.ents:\n",
    "    corpus_A_NER_counter_text.update([ent.text])\n",
    "    corpus_A_NER_counter_label.update([ent.label_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc97c09",
   "metadata": {},
   "source": [
    "#### Named-Entities (Individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_A_NER_counter_text.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8974c39e",
   "metadata": {},
   "source": [
    "#### Named-Entities (Kategorien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_A_NER_counter_label.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86e83a4",
   "metadata": {},
   "source": [
    "### NER: Corpus Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f4e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_B_NER_counter_text = Counter() \n",
    "corpus_B_NER_counter_label = Counter()\n",
    "\n",
    "for ent in docs_B.ents:\n",
    "    corpus_B_NER_counter_text.update([ent.text])\n",
    "    corpus_B_NER_counter_label.update([ent.label_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0949b6d",
   "metadata": {},
   "source": [
    "#### Named-Entities (Individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9fc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_B_NER_counter_text.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b4b0a0",
   "metadata": {},
   "source": [
    "#### Named-Entities (Kategorien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_B_NER_counter_label.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f83aa8",
   "metadata": {},
   "source": [
    "### Visualization / Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con = pd.DataFrame(corpus_A_NER_counter_label.most_common(10), columns=['entity', 'amount'])\n",
    "df_lib = pd.DataFrame(corpus_B_NER_counter_label.most_common(10), columns=['entity', 'amount'])\n",
    "df_con['corpus'] = 'conservative'\n",
    "df_lib['corpus'] = 'liberal'\n",
    "\n",
    "df = pd.concat([df_con, df_lib])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2754d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "sns.barplot(\n",
    "    data=df,\n",
    "    x='amount', y='entity', hue=\"corpus\",\n",
    "    palette={'conservative': 'r', 'liberal': 'b'},\n",
    "     alpha=.8\n",
    ")\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(xlabel=\"Abs. Freq.\", ylabel='NER Category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade4dae",
   "metadata": {},
   "source": [
    "## 2.2 Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_A_BoW = Counter() \n",
    "corpus_B_BoW = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f84064",
   "metadata": {},
   "source": [
    "### Word Cloud and BoW  Corpus Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ba5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(width=800, height=400, background_color=\"white\", min_word_length=3).generate(docs_A.text.lower())\n",
    "plt.figure(figsize=(40,80))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b19aad",
   "metadata": {},
   "source": [
    "### Word Cloud and BoW Corpus Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(width=800, height=400, background_color=\"white\", min_word_length=3).generate(docs_B.text.lower())\n",
    "plt.figure(figsize=(40,80))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427d232",
   "metadata": {},
   "source": [
    "## 2.3 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee643785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e3ebf",
   "metadata": {},
   "source": [
    "### Sentiment Analyse: Corpus Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = 0\n",
    "neg_sentences_A = \"\"\n",
    "neg_sentences_A_list = list()\n",
    "\n",
    "for title in titles_corpus_A:\n",
    "    polarity = TextBlob(title).sentiment.polarity\n",
    "    if polarity < 0:\n",
    "        negatives += 1\n",
    "        neg_sentences_A += title + \" \"\n",
    "        neg_sentences_A_list.append(title)\n",
    "\n",
    "print(f'{negatives/len(titles_corpus_A)*100:.2f}% der Titel sind negativ.')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abe46d",
   "metadata": {},
   "source": [
    "### Sentiment Analyse: Corpus Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04addf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = 0\n",
    "neg_sentences_B = \"\"\n",
    "neg_sentences_B_list = list()\n",
    "\n",
    "for title in titles_corpus_B:\n",
    "    polarity = TextBlob(title).sentiment.polarity\n",
    "    if polarity < 0:\n",
    "        negatives += 1\n",
    "        neg_sentences_B += title + \" \"\n",
    "        neg_sentences_B_list.append(title)\n",
    "\n",
    "print(f'{negatives/len(titles_corpus_B)*100:.2f}% der Titel sind negativ.')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b7550",
   "metadata": {},
   "source": [
    "### Word Cloud: Negative Sentences Corpus Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(width=800, height=400, background_color=\"white\", min_word_length=3).generate(neg_sentences_A.lower())\n",
    "plt.figure(figsize=(40,80))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083af51",
   "metadata": {},
   "source": [
    "### Word Cloud: Negative Sentences Corpus Liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec72e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(width=800, height=400, background_color=\"white\", min_word_length=3).generate(neg_sentences_B.lower())\n",
    "plt.figure(figsize=(40,80))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a683c432",
   "metadata": {},
   "source": [
    "# Qualitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ecd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus Conservative\n",
    "random.shuffle(neg_sentences_A_list)\n",
    "neg_sentences_A_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfa2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus Liberal\n",
    "random.shuffle(neg_sentences_B_list)\n",
    "neg_sentences_B_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687a57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
